# src/video_processor.py
import cv2
import numpy as np
import os
# from tqdm import tqdm  # ç§»é™¤è¿™è¡Œ
from config import VIDEO_CONFIG


class VideoProcessor:
    """è§†é¢‘å¤„ç†å™¨ - å¤„ç†è§†é¢‘æ–‡ä»¶å¹¶æå–å§¿æ€åºåˆ—"""

    def __init__(self, pose_estimator, config=None):
        self.pose_estimator = pose_estimator
        self.config = config or VIDEO_CONFIG

    def process_video(self, video_path, max_frames=None):
        """å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œæå–å§¿æ€å…³é”®ç‚¹åºåˆ—"""
        print(f"ðŸ“¹ å¤„ç†è§†é¢‘: {video_path}")

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        cap = None
        try:
            # æ‰“å¼€è§†é¢‘æ–‡ä»¶
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

            # èŽ·å–è§†é¢‘ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = total_frames / fps if fps > 0 else 0

            max_frames = max_frames or self.config.get("max_frames", 1000)
            total_frames = min(total_frames, max_frames)

            print(f"  åˆ†è¾¨çŽ‡: {width}x{height}")
            print(f"  å¸§çŽ‡: {fps:.1f} FPS")
            print(f"  æ€»å¸§æ•°: {total_frames}")
            print(f"  æ—¶é•¿: {duration:.1f}ç§’")

            # å¤„ç†è§†é¢‘å¸§
            landmarks_sequence = []
            valid_frames = 0

            # ä½¿ç”¨ç®€å•çš„è¿›åº¦æ˜¾ç¤ºï¼Œä¸ä½¿ç”¨tqdm
            print("  å¤„ç†è¿›åº¦: ", end="", flush=True)
            progress_interval = max(1, total_frames // 10)  # æ¯10%æ˜¾ç¤ºä¸€æ¬¡

            for frame_idx in range(total_frames):
                ret, frame = cap.read()
                if not ret:
                    break

                # å¤„ç†å½“å‰å¸§
                landmarks = self.pose_estimator.process_frame(frame)
                if landmarks is not None:
                    landmarks_sequence.append(landmarks)
                    valid_frames += 1

                # æ˜¾ç¤ºç®€å•è¿›åº¦
                if frame_idx % progress_interval == 0:
                    print("â–ˆ", end="", flush=True)

            cap.release()
            print()  # æ¢è¡Œ

            print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼Œæå–åˆ° {len(landmarks_sequence)} å¸§æœ‰æ•ˆå§¿æ€æ•°æ®")

            # ç»Ÿä¸€è¿”å›žæ ¼å¼
            return {
                'keypoints': np.array(landmarks_sequence),
                'landmarks_sequence': np.array(landmarks_sequence),
                'frame_indices': np.arange(len(landmarks_sequence)),
                'fps': fps,
                'total_frames': total_frames,
                'processed_frames': valid_frames,
                'detection_rate': valid_frames / total_frames if total_frames > 0 else 0,
                'video_path': video_path,
                'video_name': os.path.basename(video_path),
                'resolution': (width, height),
                'duration': duration,
                'video_info': {
                    'fps': fps,
                    'total_frames': total_frames,
                    'duration': duration,
                    'valid_frames': valid_frames,
                    'detection_rate': valid_frames / total_frames if total_frames > 0 else 0
                }
            }

        except Exception as e:
            if cap is not None:
                cap.release()
            raise e